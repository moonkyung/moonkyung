---
---

@inproceedings{10.1145/3579371.3589051,
  abbr={ISCA},
  bibtex_show={true},
  selected={true},
  pdf={isca23_dtl.pdf},
author = {Jin, Wenjing and Jang, Wonsuk and Park, Haneul and Lee, Jongsung and Kim, Soosung and Lee, Jae W.},
title = {DRAM Translation Layer: Software-Transparent DRAM Power Savings for Disaggregated Memory},
year = {2023},
isbn = {9798400700958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579371.3589051},
doi = {10.1145/3579371.3589051},
abstract = {Memory disaggregation is a promising solution to scale memory capacity and bandwidth shared by multiple server nodes in a flexible and cost-effective manner. DRAM power consumption, which is reported to be around 40\% of the total system power in the datacenter server, will become an even more serious concern in this high-capacity environment. Exploiting the low average utilization of DRAM capacity in today's datacenters, it is appealing to put unallocated/cold DRAM ranks into a power-saving mode. However, the conventional DRAM address mapping with fine-grained interleaving to maximize rank-level parallelism is incompatible with such rank-level DRAM power management techniques. Furthermore, existing DRAM power-saving techniques often require intrusive changes to the system stack, including OS, memory controller (MC), or even DRAM devices, to pose additional challenges for deployment. Thus, we propose DRAM Translation Layer (DTL) for host software/MC-transparent DRAM power management with commodity DRAM devices. Inspired by Flash Translation Layer (FTL) in modern SSDs, DTL is placed in the CXL memory controller to provide (i) flexible address mappings between host physical address and DRAM device physical address and (ii) host-transparent memory page migration. Leveraging DTL, we propose two DRAM power-saving techniques with different temporal granularities to maximize the number of DRAM ranks that can enter low-power states while provisioning sufficient DRAM bandwidth: rank-level power-down and hotness-aware self-refresh. The first technique consolidates unallocated memory pages into a subset of ranks at deallocation of a virtual machine (VM) and turns them off transparently to both OS and host MC. Our evaluation with CloudSuite benchmarks demonstrates that this technique saves DRAM power by 31.6\% on average at a 1.6\% performance cost. The hotness-aware self-refresh scheme further reduces DRAM energy consumption by up to 14.9\% with negligible performance loss via opportunistically migrating cold pages into a rank and making it enter self-refresh mode.},
booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
articleno = {16},
numpages = {13},
keywords = {DRAM, power management, datacenters, disaggregated memory, CXL, pooled memory, address translation},
location = {Orlando, FL, USA},
series = {ISCA '23}
}


@INPROCEEDINGS{9138992,
  abbr={ISCA},
  bibtex_show={true},
  selected={true},
  pdf={isca20_hwdp.pdf},
  cofirst={true},
  author={Lee*, Gyusun and Jin*, Wenjing and Song, Wonsuk and Gong, Jeonghun and Bae, Jonghyun and Ham, Tae Jun and Lee, Jae W. and Jeong, Jinkyu},
  booktitle={2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)},
  title={A Case for Hardware-Based Demand Paging},
  year={2020},
  volume={},
  number={},
  pages={1103-1116},
  keywords={demand paging;virtual memory;page fault;operating systems;CPU architecture;hardware extension},
  doi={10.1109/ISCA45697.2020.00093}
}


@inproceedings {234926,
  abbr={ATC},
  bibtex_show={true},
  selected={true},
  pdf={act19_erase-suspension.pdf},
author = {Shine Kim and Jonghyun Bae and Hakbeom Jang and Wenjing Jin and Jeonghun Gong and Seungyeon Lee and Tae Jun Ham and Jae W. Lee},
title = {Practical Erase Suspension for Modern Low-latency {SSDs}},
booktitle = {2019 USENIX Annual Technical Conference (USENIX ATC 19)},
year = {2019},
isbn = {978-1-939133-03-8},
address = {Renton, WA},
pages = {813--820},
url = {https://www.usenix.org/conference/atc19/presentation/kim-shine},
publisher = {USENIX Association},
month = jul
}


@ARTICLE{8770099,
  abbr={IEEE Micro},
  bibtex_show={true},
  selected={true},
  pdf={micro19_ssdstreamer.pdf},
  author={Bae, Jonghyun and Jang, Hakbeom and Gong, Jeonghun and Jin, Wenjing and Kim, Shine and Jang, Jaeyoung and Ham, Tae Jun and Jeong, Jinkyu and Lee, Jae W.},
  journal={IEEE Micro}, 
  title={SSDStreamer: Specializing I/O Stack for Large-Scale Machine Learning}, 
  year={2019},
  volume={39},
  number={5},
  pages={73-81},
  keywords={Random access memory;Metadata;Prefetching;Machine learning;Bandwidth;Nonvolatile memory;Support vector machines;Deep learning;Distributed Systems;Storage Management;Machine Learning},
  doi={10.1109/MM.2019.2930497}
}


@INPROCEEDINGS{8257921,
  abbr={Big Data},
  bibtex_show={true},
  selected={true},
  pdf={bigdata17_wasp.pdf},
  author={Bae, Jonghyun and Jang, Hakbeom and Jin, Wenjing and Heo, Jun and Jang, Jaeyoung and Hwang, Joo-Young and Cho, Sangyeun and Lee, Jae W.},
  booktitle={2017 IEEE International Conference on Big Data (Big Data)}, 
  title={Jointly Optimizing Task Granularity and Concurrency for In-memory MapReduce Frameworks}, 
  year={2017},
  volume={},
  number={},
  pages={130-140},
  keywords={Sparks;Guidelines;Runtime;Concurrent computing;Tuning;Robustness},
  doi={10.1109/BigData.2017.8257921}
}


